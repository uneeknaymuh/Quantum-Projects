{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aJ_pmgxvGur9"
   },
   "source": [
    "# Hands-on session 1 - Variational Auto-Encoders\n",
    "## Generative Modeling Summer School 2024"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RvsuVNczG6pP"
   },
   "source": [
    "### Theory behind VAEs\n",
    "\n",
    "VAEs are latent variable models trained with variational inference. In general, the latent variable models define the following generative process:\n",
    "\\begin{align}\n",
    "1.\\ & \\mathbf{z} \\sim p_{\\lambda}(\\mathbf{z}) \\\\\n",
    "2.\\ & \\mathbf{x} \\sim p_{\\theta}(\\mathbf{x}|\\mathbf{z})\n",
    "\\end{align}\n",
    "\n",
    "In plain words, we assume that for observable data $\\mathbf{x}$, there are some latent (hidden) factors $\\mathbf{z}$. Then, the training objective is the log-likelihood function of the following form:\n",
    "$$\n",
    "\\log p_{\\vartheta}(\\mathbf{x})=\\log \\int p_\\theta(\\mathbf{x} \\mid \\mathbf{z}) p_\\lambda(\\mathbf{z}) \\mathrm{d} \\mathbf{z} .\n",
    "$$\n",
    "\n",
    "The problem here is the intractability of the integral if the dependencies between random variables $\\mathbf{x}$ and $\\mathbf{z}$ are non-linear and/or the distributions are non-Gaussian.\n",
    "\n",
    "By introducing variational posteriors $q_{\\phi}(\\mathbf{z}|\\mathbf{x})$, we get the following lower bound (the Evidence Lower Bound, ELBO):\n",
    "$$\n",
    "\\log p_{\\vartheta}(\\mathbf{x}) \\geq \\mathbb{E}_{\\mathbf{z} \\sim q_\\phi(\\mathbf{z} \\mid \\mathbf{x})}\\left[\\log p_\\theta(\\mathbf{x} \\mid \\mathbf{z})\\right]-\\mathrm{KL}\\left(q_\\phi(\\mathbf{z} \\mid \\mathbf{x}) \\| p_\\lambda(\\mathbf{z})\\right) .\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "suzhlbWqxtD9"
   },
   "source": [
    "## IMPORTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "executionInfo": {
     "elapsed": 293,
     "status": "ok",
     "timestamp": 1718298589164,
     "user": {
      "displayName": "shawn gibford",
      "userId": "13602589974876645014"
     },
     "user_tz": -120
    },
    "id": "qy16_WTM_-fO"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torchsummary in /home/orquestra/.local/lib/python3.11/site-packages (1.5.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install torchsummary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9132,
     "status": "ok",
     "timestamp": 1718298599181,
     "user": {
      "displayName": "shawn gibford",
      "userId": "13602589974876645014"
     },
     "user_tz": -120
    },
    "id": "XlmfL6-2BOvw",
    "outputId": "8520092d-8920-4a7f-f8b0-1385702caf19",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pytorch_model_summary in /home/orquestra/.local/lib/python3.11/site-packages (0.1.2)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/site-packages (from pytorch_model_summary) (4.66.4)\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.11/site-packages (from pytorch_model_summary) (2.2.2)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.11/site-packages (from pytorch_model_summary) (1.26.4)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/site-packages (from torch->pytorch_model_summary) (3.14.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/site-packages (from torch->pytorch_model_summary) (4.12.0)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.11/site-packages (from torch->pytorch_model_summary) (1.9)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/site-packages (from torch->pytorch_model_summary) (3.3)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/site-packages (from torch->pytorch_model_summary) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/site-packages (from torch->pytorch_model_summary) (2024.3.1)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.11/site-packages (from torch->pytorch_model_summary) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.11/site-packages (from torch->pytorch_model_summary) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.11/site-packages (from torch->pytorch_model_summary) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.11/site-packages (from torch->pytorch_model_summary) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.11/site-packages (from torch->pytorch_model_summary) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.11/site-packages (from torch->pytorch_model_summary) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.11/site-packages (from torch->pytorch_model_summary) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.11/site-packages (from torch->pytorch_model_summary) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.11/site-packages (from torch->pytorch_model_summary) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.11/site-packages (from torch->pytorch_model_summary) (2.19.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.11/site-packages (from torch->pytorch_model_summary) (12.1.105)\n",
      "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.11/site-packages (from torch->pytorch_model_summary) (2.2.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.11/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->pytorch_model_summary) (12.5.40)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/site-packages (from jinja2->torch->pytorch_model_summary) (2.1.5)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.11/site-packages (from sympy->torch->pytorch_model_summary) (1.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pytorch_model_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1718298599181,
     "user": {
      "displayName": "shawn gibford",
      "userId": "13602589974876645014"
     },
     "user_tz": -120
    },
    "id": "BjxkigYLxpB7"
   },
   "outputs": [],
   "source": [
    "# DO NOT REMOVE!\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torchvision\n",
    "from torchvision.datasets import MNIST\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import models\n",
    "from torchsummary import summary\n",
    "from pytorch_model_summary import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1718298599182,
     "user": {
      "displayName": "shawn gibford",
      "userId": "13602589974876645014"
     },
     "user_tz": -120
    },
    "id": "Cm23hRm6CqGh",
    "outputId": "de73cec0-36e2-4940-c016-031950bd689d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The available device is cpu\n"
     ]
    }
   ],
   "source": [
    "# Check if GPU is available and determine the device\n",
    "if torch.cuda.is_available():\n",
    "  device = 'cuda'\n",
    "else:\n",
    "  device = 'cpu'\n",
    "\n",
    "print(f'The available device is {device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3677,
     "status": "ok",
     "timestamp": 1718298602857,
     "user": {
      "displayName": "shawn gibford",
      "userId": "13602589974876645014"
     },
     "user_tz": -120
    },
    "id": "81CxONpmMulC",
    "outputId": "a35b987a-6a32-426d-b0d2-aafbbd422d9c"
   },
   "outputs": [],
   "source": [
    "# mount drive: WE NEED IT FOR SAVING IMAGES!\n",
    "#from google.colab import drive\n",
    "#drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1718298602857,
     "user": {
      "displayName": "shawn gibford",
      "userId": "13602589974876645014"
     },
     "user_tz": -120
    },
    "id": "OoPb92zNM4UY"
   },
   "outputs": [],
   "source": [
    "# PLEASE CHANGE IT TO YOUR OWN GOOGLE DRIVE!\n",
    "images_dir = 'home/orquestra/dtu/hw/results/vae/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I3zs31tOyCmq"
   },
   "source": [
    "## Auxiliary functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DF0agzL7tDHK"
   },
   "source": [
    "Let us define some useful log-distributions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1718298602857,
     "user": {
      "displayName": "shawn gibford",
      "userId": "13602589974876645014"
     },
     "user_tz": -120
    },
    "id": "LIBNVRNJtHSd"
   },
   "outputs": [],
   "source": [
    "# DO NOT REMOVE\n",
    "PI = torch.from_numpy(np.asarray(np.pi))\n",
    "EPS = 1.e-5\n",
    "\n",
    "\n",
    "def log_categorical(x, p, num_classes=256, reduction=None, dim=None):\n",
    "    x_one_hot = F.one_hot(x.long(), num_classes=num_classes)\n",
    "    log_p = x_one_hot * torch.log(torch.clamp(p, EPS, 1. - EPS))\n",
    "    if reduction == 'mean':\n",
    "        return torch.mean(log_p, dim)\n",
    "    elif reduction == 'sum':\n",
    "        return torch.sum(log_p, dim)\n",
    "    else:\n",
    "        return log_p\n",
    "\n",
    "\n",
    "def log_bernoulli(x, p, reduction=None, dim=None):\n",
    "    pp = torch.clamp(p, EPS, 1. - EPS)\n",
    "    log_p = x * torch.log(pp) + (1. - x) * torch.log(1. - pp)\n",
    "    if reduction == 'mean':\n",
    "        return torch.mean(log_p, dim)\n",
    "    elif reduction == 'sum':\n",
    "        return torch.sum(log_p, dim)\n",
    "    else:\n",
    "        return log_p\n",
    "\n",
    "\n",
    "def log_normal_diag(x, mu, log_var, reduction=None, dim=None):\n",
    "    D = x.shape[1]\n",
    "    log_p = -0.5 * D * torch.log(2. * PI) - 0.5 * log_var - 0.5 * torch.exp(-log_var) * (x - mu)**2.\n",
    "    if reduction == 'mean':\n",
    "        return torch.mean(log_p, dim)\n",
    "    elif reduction == 'sum':\n",
    "        return torch.sum(log_p, dim)\n",
    "    else:\n",
    "        return log_p\n",
    "\n",
    "\n",
    "def log_standard_normal(x, reduction=None, dim=None):\n",
    "    D = x.shape[1]\n",
    "    log_p = -0.5 * D * torch.log(2. * PI) - 0.5 * x**2.\n",
    "    if reduction == 'mean':\n",
    "        return torch.mean(log_p, dim)\n",
    "    elif reduction == 'sum':\n",
    "        return torch.sum(log_p, dim)\n",
    "    else:\n",
    "        return log_p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q2LLOs0kn7iw"
   },
   "source": [
    "## Implementing VAEs\n",
    "\n",
    "The goal of this assignment is to implement four classes:\n",
    "- `Encoder`: this class implements the encoder (variational posterior), $q_{\\phi}(\\mathbf{z}|\\mathbf{x})$.\n",
    "- `Decoder`: this class implements the decoded (the conditional likelihood), $p_{\\theta}(\\mathbf{x}|\\mathbf{z})$.\n",
    "- `Prior`: this class implements the marginal over latents (the prior), $p_{\\lambda}(\\mathbf{z})$.\n",
    "- `VAE`: this class combines all components."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7cXhOwKAzW6Z"
   },
   "source": [
    "### Encoder\n",
    "We start with `Encoder`. Please remember that we assume the Gaussian variational posterior with a diagonal covariance matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "executionInfo": {
     "elapsed": 320,
     "status": "ok",
     "timestamp": 1718299392016,
     "user": {
      "displayName": "shawn gibford",
      "userId": "13602589974876645014"
     },
     "user_tz": -120
    },
    "id": "MrwQXSuEoFfH"
   },
   "outputs": [],
   "source": [
    "# YOUR CODE GOES HERE\n",
    "# NOTE: The class must containt the following functions:\n",
    "# (i) reparameterization\n",
    "# (ii) sample\n",
    "# (iii) log_prob\n",
    "# Moreover, forward must return the log-probability of the variational posterior for given x, i.e., log q(z|x)\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, encoder_net):  # ADD APPROPRIATE ATTRIBUTES\n",
    "        super(Encoder, self).__init__()\n",
    "        self.encoder = encoder_net\n",
    "\n",
    "\n",
    "    @staticmethod\n",
    "    def reparameterization(mu, log_var):\n",
    "        std = torch.exp(0.5 * log_var)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mu + eps * std\n",
    "\n",
    "    def encode(self, x):\n",
    "        # FILL IN if you think it's necessary\n",
    "        # output: mean, (log-)variance\n",
    "        h_e = self.encoder(x)\n",
    "        mu_e, log_var_e = torch.chunk(h_e, 2, dim=1)\n",
    "\n",
    "        return mu_e, log_var_e\n",
    "\n",
    "\n",
    "    def sample(self, x=None, mu_e=None, log_var_e=None):\n",
    "        # FILL IN\n",
    "        # output: z\n",
    "        if (mu_e is None) and (log_var_e is None):\n",
    "            mu_e, log_var_e = self.encode(x)\n",
    "        else:\n",
    "            if (mu_e is None) or (log_var_e is None):\n",
    "                raise ValueError('mu and log-var cant be None!')\n",
    "        z = self.reparameterization(mu_e, log_var_e)\n",
    "        return z\n",
    "\n",
    "\n",
    "    def log_prob(self, x=None, mu_e=None, log_var_e=None, z=None):\n",
    "        if x is not None:\n",
    "            mu_e, log_var_e = self.encode(x)\n",
    "            z = self.sample(mu_e=mu_e,log_var_e=log_var_e)\n",
    "        else:\n",
    "            if (mu_e is None) or (log_var_e is None) or (z is None):\n",
    "              raise ValueError('mu, log-var, and z cant be None')\n",
    "\n",
    "        return log_normal_diag(z, mu_e, log_var_e)\n",
    "\n",
    "\n",
    "    def forward(self, x, type='log_prob'):\n",
    "        # FILL IN\n",
    "        assert type in ['encode', 'log_prob'], 'type could be either encode or log-prob'\n",
    "        if type == 'log-prob':\n",
    "            return self.log_prob(x)\n",
    "        else:\n",
    "            return self.sample(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8XVlH5OUzdgJ"
   },
   "source": [
    "Please answer the following questions:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D1BNAH02zjjt"
   },
   "source": [
    "#### Question 1\n",
    "\n",
    "Please explain the reparameterization trick and provide a mathematical formula."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UlxYq7-gzo_o"
   },
   "source": [
    "ANSWER: The reparameterization trick is a solution to the issue of backcalculation not able to compute the derivative through a \"random node\". By taking an independent random variable with a simple distribution, we can perform simple operations on it such that we can express that transformation as a new 'random' variable.\n",
    "\n",
    "Guassian variable = $z$ \\\\\n",
    "mean = $\\mu$ \\\\\n",
    "varience = $\\sigma^2$ \\\\\n",
    "idd varible = $\\epsilon \\sim ‚Ñï(\\epsilon|0,1)$\n",
    "\n",
    "\\begin{equation}\n",
    "  z = \\mu + \\sigma \\cdot \\epsilon\n",
    "\\end{equation}\n",
    "\n",
    "By sampling $\\epsilon$ from this transformation, we are able to sample $‚Ñï(z|\\mu,\\sigma)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HpRgXdtBzt3-"
   },
   "source": [
    "#### Question 2\n",
    "\n",
    "Please write down mathematically the log-probability of the encoder (variational posterior).\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ET-mMAg10Ewv"
   },
   "source": [
    "ANSWER:\n",
    "\n",
    "$\\log q_\\phi(z|x) = -\\frac{1}{2} \\sum_{j=1}^{J} \\left[ \\log(2\\pi) + \\log(\\sigma_j^2) + \\frac{(z_j - \\mu_j)^2}{\\sigma_j^2} \\right]\n",
    "$\n",
    "\n",
    "\n",
    "\n",
    "$\\log q_\\phi(z|x)$ denotes the log-probability of the latent variable $z$ given the input $x$\n",
    "\n",
    "\n",
    "$\\phi$ represents the parameters of the encoder\n",
    "\n",
    "\n",
    "$J$ is the number of dimensions in the latent space\n",
    "\n",
    "\n",
    "$\\mu_j$ and $\\sigma_j^2$ are the mean and variance for the $j$-th latent variable\n",
    "\n",
    "\n",
    "$z_j$ is the $j$-th component of  $z$\n",
    "\n",
    "\n",
    "The sum is taken over all latent variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nhNTy5mn0XDT"
   },
   "source": [
    "### Decoder\n",
    "\n",
    "The decoder is the conditional likelihood, i.e., $p(x|z)$. Please remember that we must decide on the form of the distribution (e.g., Bernoulli, Gaussian, Categorical)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "executionInfo": {
     "elapsed": 299,
     "status": "ok",
     "timestamp": 1718299724120,
     "user": {
      "displayName": "shawn gibford",
      "userId": "13602589974876645014"
     },
     "user_tz": -120
    },
    "id": "9vTmKHwrpUVa"
   },
   "outputs": [],
   "source": [
    "# YOUR CODE GOES HERE\n",
    "# NOTE: The class must containt the following functions:\n",
    "# (i) sample\n",
    "# (ii) log_prob\n",
    "# Moreover, forward must return the log-probability of the conditional likelihood function for given z, i.e., log p(x|z)\n",
    "# Additionally, please specify the distribution class you want to use for the decode (i.e. the `distribution` attribute)\n",
    "\n",
    "num_vals=1\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, decoder_net, distribution='bernoulli', num_vals=num_vals): # ADD APPROPRIATE ATTRIBUTES\n",
    "        super(Decoder, self).__init__()\n",
    "\n",
    "        self.decoder = decoder_net\n",
    "        self.distribution = distribution\n",
    "        self.num_vals=num_vals\n",
    "\n",
    "    def decode(self, z):\n",
    "        # FILL IN if you think it's necessary\n",
    "        # output: parameters of the distribution p(x|z)\n",
    "        h_d = self.decoder(z)\n",
    "\n",
    "        if self.distribution == 'categorical':\n",
    "          b = h_d.shape[0]\n",
    "          d = h_d.shape[1]//self.num_vals\n",
    "          h_d = h_d.view(b,d, self.num_vals)\n",
    "          mu_d = torch.softmax(h_d, 2)\n",
    "          return [mu_d]\n",
    "\n",
    "        elif self.distribution == 'bernoulli':\n",
    "            mu_d = torch.sigmoid(h_d)\n",
    "            return [mu_d]\n",
    "        else:\n",
    "            raise ValueError('Either Catergorical or Bernoulli')\n",
    "\n",
    "    def sample(self, z):\n",
    "        # FILL IN\n",
    "        # output: a sample from p(x|z)\n",
    "        outs = self.decode(z)\n",
    "\n",
    "        if self.distribution == 'categorical':\n",
    "            mu_d = outs[0]\n",
    "            b = mu_d.shape[0]\n",
    "            m = mu_d.shape[1]\n",
    "            mu_d = mu_d.view(mu_d.shape[0], -1, self.num_vals)\n",
    "            p = mu_d.view(-1, self.num_vals)\n",
    "            x_new = torch.multinomial(p, num_samples=1).view(b, m)\n",
    "\n",
    "        elif self.distribution == 'bernoulli':\n",
    "            mu_d = outs[0]\n",
    "            x_new = torch.bernoulli(mu_d)\n",
    "\n",
    "        else:\n",
    "            raise ValueError('Either categorical or bernoulli')\n",
    "\n",
    "        return x_new\n",
    "\n",
    "    def log_prob(self, x, z):\n",
    "        # FILL IN\n",
    "        # output: log p(x|z)\n",
    "        outs = self.decode(z)\n",
    "\n",
    "        if self.distribution == 'categorical':\n",
    "            mu_d = outs[0]\n",
    "            log_p = log_categorical(x, mu_d, num_classes=self.num_vals, reduction='sum', dim=-1).sum(-1)\n",
    "\n",
    "        elif self.distribution == 'bernoulli':\n",
    "            mu_d = outs[0]\n",
    "            log_p = log_bernoulli(x, mu_d, reduction='sum', dim=-1)\n",
    "\n",
    "        else:\n",
    "            raise ValueError('Either `categorical` or `bernoulli`')\n",
    "\n",
    "        return log_p\n",
    "\n",
    "    def forward(self, z, x=None, type='log_prob'):\n",
    "        # FILL IN\n",
    "        assert type in ['decoder', 'log_prob'], 'Type could be either decode or log_prob'\n",
    "        if type == 'log_prob':\n",
    "            return self.log_prob(x, z)\n",
    "        else:\n",
    "            return self.sample(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5xjbNkNL01DP"
   },
   "source": [
    "Please answer the following questions:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qjDvPaBj04cA"
   },
   "source": [
    "#### Question 3\n",
    "\n",
    "Please explain your choice of distribution for image data used in this assignment. Additionally, please write it down mathematically (if you think that presenting it as the log-probability, then please do it)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HLZEzmGI1Ok-"
   },
   "source": [
    "ANSWER:\n",
    "\n",
    "Mathematically, the Bernoulli distribution for a single pixel can be expressed as:\n",
    "\n",
    "\\begin{equation}\n",
    "P(X=x)=p^{x}(1‚àíp)^{1‚àíx}\n",
    "\\end{equation}\n",
    "\n",
    "where ( $x$ ) is the value of the pixel ($0$ or $1$), and ( $p$ ) is the probability of the pixel being $1$ (white).\n",
    "When presenting this in terms of log-probability, which is often used in VAEs to compute the reconstruction loss during training, the expression becomes:\n",
    "\n",
    "\\begin{equation}\n",
    "\\log P(X=x)=x \\log (p)+(1‚àíx)\\log (1‚àíp)\n",
    "\\end{equation}\n",
    "\n",
    "This log-probability is used because it simplifies the multiplication of probabilities into a sum of log-probabilities, which is numerically more stable and efficient for computation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RhbWamId1eGt"
   },
   "source": [
    "#### Question 4\n",
    "\n",
    "Please explain how one can sample from the distribution chosen by you. Please be specific and formal (i.e., provide mathematical formulae)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9-3gxJosFXv4"
   },
   "source": [
    "ANSWER:\n",
    "\n",
    "1. Determine the probability of success ( $p$ ), which is the probability that a pixel will be white ($1$).\n",
    "\n",
    "\n",
    "2. Generate a random number ( $u$ ) from a uniform distribution in the interval $[0, 1]$.\n",
    "\n",
    "\n",
    "3. Compare ( $u$ ) to ( $p$ ):\n",
    "\n",
    "If ( $u \\leq p$ ), then sample a 1 (white pixel).\n",
    "If ( $u > p$ ), then sample a 0 (black pixel).\n",
    "\n",
    "\n",
    "\n",
    "Mathematically, the sampling process can be represented as:\n",
    "\n",
    "\n",
    "$X =\\begin{cases}\n",
    "1 & \\text{if } u \\leq p \\\\\n",
    "0 & \\text{if } u > p\n",
    "\\end{cases}$\n",
    "\n",
    "\n",
    "where ( $X$ ) is the sampled value from the Bernoulli distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CLIEwIiw00op"
   },
   "source": [
    "### Prior\n",
    "\n",
    "The prior is the marginal distribution over latent variables, i.e., $p(z)$. It plays a crucial role in the generative process and also in synthesizing images of better quality.\n",
    "\n",
    "In this assignment, you are asked to implement a prior that is learnable (e.g., parameterized by neural networks). If you decide to implement the standard Gaussian prior only, then please be aware that you will not get any points.\n",
    "\n",
    "For the learnable prior you can choose the **Mixture of Gaussians**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "executionInfo": {
     "elapsed": 353,
     "status": "ok",
     "timestamp": 1718299731980,
     "user": {
      "displayName": "shawn gibford",
      "userId": "13602589974876645014"
     },
     "user_tz": -120
    },
    "id": "xQIvee5Cp69V"
   },
   "outputs": [],
   "source": [
    "# YOUR CODE GOES HERE\n",
    "# NOTES:\n",
    "# (i) The function \"sample\" must be implemented.\n",
    "# (ii) The function \"forward\" must return the log-probability, i.e., log p(z)\n",
    "\n",
    "class Prior(nn.Module):\n",
    "    def __init__(self, L): # ADD APPROPRIATE ATTRIBUTES\n",
    "        # FILL IN\n",
    "        super(Prior, self).__init__()\n",
    "        self.L = L\n",
    "\n",
    "    def sample(self, batch_size=16):\n",
    "        # FILL IN\n",
    "        # output: a sample from p(z)\n",
    "        z = torch.randn((batch_size, self.L))\n",
    "        return z\n",
    "\n",
    "    def log_prob(self, z): #I dont think this is right, check this out later\n",
    "        # FILL IN\n",
    "        # output: log p(z)\n",
    "        return log_standard_normal(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z0KH9f2O_PDg"
   },
   "source": [
    "#### Question 5\n",
    "\n",
    "**Option 1:  Standard Gaussian**\n",
    "\n",
    "- Please explain the choice of your prior and write it down mathematically.\n",
    "\n",
    "**Option 2: Mixture of Gaussians**\n",
    "\n",
    "Please do the following:\n",
    "- Please explain the choice of your prior and write it down mathematically.\n",
    "- Please write down its sampling procedure (if necessary, please add a code snippet).\n",
    "- Please write down its log-probability (a mathematical formula)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9gXWplP1NpoM"
   },
   "source": [
    "1. Mixture of Gaussians (MoG) is more flexible and can model complexities in the latent space better than a standard Gaussian.\n",
    "\n",
    "\\begin{equation}p(z)= \\sum_{k=1}^{K} \\pi_{k}  ‚Ñï (z|\\mu_{k},\\sigma_{k}^2)\\end{equation}\n",
    "\n",
    "\n",
    "\n",
    "*   $p(z)$ is the probability density of the latent variable $z$\n",
    "\n",
    "* $\\pi_k$ are the mixing coefficients\n",
    "that sum to $1$\n",
    "\n",
    "* $‚Ñï(z | \\mu_k, \\sigma_k^2)$  is the Gaussian distribution with mean $\\mu_k$  and variance $\\sigma_k^2$\n",
    "\n",
    "* $K$ is the number of mixture components\n",
    "\n",
    "2. First, select mixture compent according to the mixing coefficients, $\\pi_k$, and then sampling from the selected Gaussian distribution.\n",
    "\n",
    "\n",
    "\n",
    "```\n",
    "def mog(n_samples, mixingco, means, variences):\n",
    "\n",
    "  #choosing components\n",
    "  comp_indx = np.random.choice(len(mixingco), size=n_samples, p=mixingco)\n",
    "\n",
    "  #sample from gaussian\n",
    "  samples = np.random.normal(loc=means[comp_indx], scale=np.sqrt(variences[comp_indx]))\n",
    "\n",
    "  return samples\n",
    "```\n",
    "\n",
    "\n",
    "3. \\begin{equation}\n",
    "\\log p(z) = \\log \\left( \\sum_{k=1}^{K} exp(\\log (\\pi_k) + \\log ‚Ñï(z|\\mu_k, \\sigma_{k}^2))\\right)\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aOM4QM9I_62d"
   },
   "source": [
    "### Complete VAE\n",
    "\n",
    "The last class is `VAE` tha combines all components. Please remember that this class must implement the **Negative ELBO** in `forward`, as well as `sample` (*hint*: it is a composition of `sample` functions from the prior and the decoder)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "executionInfo": {
     "elapsed": 297,
     "status": "ok",
     "timestamp": 1718300966020,
     "user": {
      "displayName": "shawn gibford",
      "userId": "13602589974876645014"
     },
     "user_tz": -120
    },
    "id": "OQpf-BeSqA6V"
   },
   "outputs": [],
   "source": [
    "# YOUR CODE GOES HERE\n",
    "# This class combines Encoder, Decoder and Prior.\n",
    "# NOTES:\n",
    "# (i) The function \"sample\" must be implemented.\n",
    "# (ii) The function \"forward\" must return the negative ELBO. Please remember to add an argument \"reduction\", which is either \"mean\" or \"sum\".\n",
    "class VAE(nn.Module):\n",
    "    def __init__(self, encoder_net, decoder_net, num_vals=1, L=32, likelihood_type='bernoulli'):\n",
    "        super(VAE, self).__init__()\n",
    "\n",
    "        self.encoder = Encoder(encoder_net=encoder_net)\n",
    "        self.decoder = Decoder(distribution=likelihood_type, decoder_net=decoder_net, num_vals=num_vals)\n",
    "        self.prior = Prior(L=L)\n",
    "\n",
    "        self.num_vals = num_vals\n",
    "\n",
    "        self.likelihood_type = likelihood_type\n",
    "\n",
    "    def sample(self, batch_size=64):\n",
    "        z = self.prior.sample(batch_size=batch_size)\n",
    "        return self.decoder.sample(z)\n",
    "\n",
    "    def forward(self, x, reduction='avg'):\n",
    "        # FILL IN\n",
    "        # output: the negative ELBO (NELBO) that is either averaged or summed (VERY IMPORTANT!)\n",
    "        # encoder\n",
    "        mu_e, log_var_e = self.encoder.encode(x)\n",
    "        z = self.encoder.sample(mu_e=mu_e, log_var_e=log_var_e)\n",
    "\n",
    "        # ELBO\n",
    "        RE = self.decoder.log_prob(x, z)\n",
    "        KL = (self.prior.log_prob(z) - self.encoder.log_prob(mu_e=mu_e, log_var_e=log_var_e, z=z)).sum(-1)\n",
    "\n",
    "        if reduction == 'sum':\n",
    "            return -(RE + KL).sum()\n",
    "        else:\n",
    "            return -(RE + KL).mean()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U9axMlEkAYN5"
   },
   "source": [
    "#### Question 6\n",
    "\n",
    "Please explain your choice of the distribution for the conditional likelihood function, and write down mathematically the log-probability of the decoder."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BgbEJm8FAuze"
   },
   "source": [
    "ANSWER:\n",
    "\n",
    "A Normal distribution would be picked if we were using continuous data. But since we are using binary data, we will continue to use a Bernoulli distribution.\n",
    "\n",
    "\n",
    "\\begin{equation}\n",
    "\\log P(x|z) = \\sum_{i=1}^{N} x_i \\log p_i + (1-x_i)\\log(1-p_i)\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eaJgXPYyAmeJ"
   },
   "source": [
    "#### Question 7\n",
    "\n",
    "Please write down mathematically the **Negative ELBO**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VzZ1CJzYWcGv"
   },
   "source": [
    "ANSWER:\n",
    "\\begin{equation}\n",
    "NELBO(x) = -ùîº_{q(z|x)}[\\log p(x|z)]+ KL[q(z|x)||p(z)]\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hLhgze7DA4yx"
   },
   "source": [
    "### Evaluation and training functions\n",
    "\n",
    "**Please DO NOT remove or modify them.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "executionInfo": {
     "elapsed": 280,
     "status": "ok",
     "timestamp": 1718300968803,
     "user": {
      "displayName": "shawn gibford",
      "userId": "13602589974876645014"
     },
     "user_tz": -120
    },
    "id": "I9Dr3a6lqJ0W"
   },
   "outputs": [],
   "source": [
    "# ==========DO NOT REMOVE==========\n",
    "\n",
    "def evaluation(test_loader, name=None, model_best=None, epoch=None):\n",
    "    # EVALUATION\n",
    "    if model_best is None:\n",
    "        # load best performing model\n",
    "        model_best = torch.load(name + '.model')\n",
    "\n",
    "    model_best.eval()\n",
    "    loss = 0.\n",
    "    N = 0.\n",
    "    for indx_batch, (test_batch, _) in enumerate(test_loader):\n",
    "        test_batch = test_batch.to(device)\n",
    "        test_batch = test_batch.view(test_batch.size(0), -1)  # Flatten the batch to (batch_size, 784)\n",
    "        loss_t = model_best.forward(test_batch, reduction='sum')\n",
    "        loss = loss + loss_t.item()\n",
    "        N = N + test_batch.shape[0]\n",
    "    loss = loss / N\n",
    "\n",
    "    if epoch is None:\n",
    "        print(f'FINAL LOSS: nll={loss}')\n",
    "    else:\n",
    "        print(f'Epoch: {epoch}, val nll={loss}')\n",
    "\n",
    "    return loss\n",
    "\n",
    "\n",
    "def samples_real(name, test_loader, shape=(28,28)):\n",
    "    # real images-------\n",
    "    num_x = 4\n",
    "    num_y = 4\n",
    "    x, _ = next(iter(test_loader))\n",
    "    x = x.to('cpu').detach().numpy()\n",
    "\n",
    "    fig, ax = plt.subplots(num_x, num_y)\n",
    "    for i, ax in enumerate(ax.flatten()):\n",
    "        plottable_image = np.reshape(x[i], shape)\n",
    "        ax.imshow(plottable_image, cmap='gray')\n",
    "        ax.axis('off')\n",
    "\n",
    "    plt.savefig(name+'_real_images.pdf', bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "def samples_generated(name, data_loader, shape=(28,28), extra_name=''):\n",
    "    x, _ = next(iter(data_loader))\n",
    "    x = x.to('cpu').detach().numpy()\n",
    "\n",
    "    # generations-------\n",
    "    model_best = torch.load(name + '.model')\n",
    "    model_best.eval()\n",
    "\n",
    "    num_x = 4\n",
    "    num_y = 4\n",
    "    x = model_best.sample(num_x * num_y)\n",
    "    x = x.to('cpu').detach().numpy()\n",
    "\n",
    "    fig, ax = plt.subplots(num_x, num_y)\n",
    "    for i, ax in enumerate(ax.flatten()):\n",
    "        plottable_image = np.reshape(x[i], shape)\n",
    "        ax.imshow(plottable_image, cmap='gray')\n",
    "        ax.axis('off')\n",
    "\n",
    "    plt.savefig(name + '_generated_images' + extra_name + '.pdf', bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "def plot_curve(name, nll_val):\n",
    "    plt.plot(np.arange(len(nll_val)), nll_val, linewidth='3')\n",
    "    plt.xlabel('epochs')\n",
    "    plt.ylabel('nll')\n",
    "    plt.savefig(name + '_nll_val_curve.pdf', bbox_inches='tight')\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1718300969889,
     "user": {
      "displayName": "shawn gibford",
      "userId": "13602589974876645014"
     },
     "user_tz": -120
    },
    "id": "9ABgMeG0qFAP"
   },
   "outputs": [],
   "source": [
    "# ==========DO NOT REMOVE==========\n",
    "\n",
    "def training(name, max_patience, num_epochs, model, optimizer, training_loader, val_loader, shape=(28,28)):\n",
    "    nll_val = []\n",
    "    best_nll = 1000.\n",
    "    patience = 0\n",
    "\n",
    "    # Main loop\n",
    "    for e in range(num_epochs):\n",
    "        # TRAINING\n",
    "        model.train()\n",
    "        for indx_batch, (batch, _) in enumerate(training_loader):\n",
    "            batch = batch.to(device)\n",
    "            batch = batch.view(batch.size(0), -1)  # Flatten the batch to (batch_size, 784)\n",
    "            loss = model.forward(batch, reduction='mean')\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        # Validation\n",
    "        loss_val = evaluation(val_loader, model_best=model, epoch=e)\n",
    "        nll_val.append(loss_val)  # save for plotting\n",
    "\n",
    "        if e == 0:\n",
    "            print('saved!')\n",
    "            torch.save(model, name + '.model')\n",
    "            best_nll = loss_val\n",
    "        else:\n",
    "            if loss_val < best_nll:\n",
    "                print('saved!')\n",
    "                torch.save(model, name + '.model')\n",
    "                best_nll = loss_val\n",
    "                patience = 0\n",
    "\n",
    "                samples_generated(name, val_loader, shape=shape, extra_name=\"_epoch_\" + str(e))\n",
    "            else:\n",
    "                patience = patience + 1\n",
    "\n",
    "        if patience > max_patience:\n",
    "            break\n",
    "\n",
    "    nll_val = np.asarray(nll_val)\n",
    "\n",
    "    return nll_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kWr8N2u2qNTu"
   },
   "source": [
    "### Setup\n",
    "\n",
    "**NOTE: *Please comment your code! Especially if you introduce any new variables (e.g., hyperparameters).***\n",
    "\n",
    "In the following cells, we define `transforms` for the dataset. Next, we initialize the data, a directory for results and some fixed hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1718300970953,
     "user": {
      "displayName": "shawn gibford",
      "userId": "13602589974876645014"
     },
     "user_tz": -120
    },
    "id": "bFTE5jtYpxDV"
   },
   "outputs": [],
   "source": [
    "# PLEASE DEFINE APPROPRIATE TRANFORMS FOR THE DATASET\n",
    "# (If you don't see any need to do that, then you can skip this cell)\n",
    "# HINT: Please prepare your data accordingly to your chosen distribution in the decoder\n",
    "transforms_train = torchvision.transforms.Compose([\n",
    "    transforms.ToTensor()])  # Convert the image to a PyTorch tensor\n",
    " \n",
    "\n",
    "transforms_test = torchvision.transforms.Compose([\n",
    "   transforms.ToTensor()])  # Convert the image to a PyTorch tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8SDcOBbGCM8z"
   },
   "source": [
    "Please do not modify the code in the next cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "executionInfo": {
     "elapsed": 277,
     "status": "ok",
     "timestamp": 1718301273854,
     "user": {
      "displayName": "shawn gibford",
      "userId": "13602589974876645014"
     },
     "user_tz": -120
    },
    "id": "UXHitzrYqNhY"
   },
   "outputs": [],
   "source": [
    "# ==========DO NOT REMOVE==========\n",
    "#-dataset\n",
    "dataset = MNIST('/home/orquestra/data/MNIST/raw', train=True, download=True,\n",
    "                      transform=transforms_train\n",
    "                )\n",
    "\n",
    "train_dataset, val_dataset = torch.utils.data.random_split(dataset, [50000, 10000], generator=torch.Generator().manual_seed(14))\n",
    "\n",
    "test_dataset = MNIST('/home/orquestra/data/MNIST/raw/', train=False, download=True,\n",
    "                      transform=transforms_test\n",
    "                     )\n",
    "#-dataloaders\n",
    "batch_size_dl = 28\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size_dl, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size_dl, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size_dl, shuffle=False)\n",
    "\n",
    "#-creating a dir for saving results\n",
    "name = 'vae'\n",
    "result_dir = '/home/orquestra/dtu/hw/results/vae/'\n",
    "if not(os.path.exists(result_dir)):\n",
    "    os.mkdir(result_dir)\n",
    "\n",
    "#-hyperparams (please do not modify them!)\n",
    "num_epochs = 1000 # max. number of epochs\n",
    "max_patience = 20 # an early stopping is used, if training doesn't improve for longer than 20 epochs, it is stopped"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kmKDXMI0B231"
   },
   "source": [
    "In the next cell, please initialize the model. Please remember about commenting your code!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 426,
     "status": "ok",
     "timestamp": 1718301276480,
     "user": {
      "displayName": "shawn gibford",
      "userId": "13602589974876645014"
     },
     "user_tz": -120
    },
    "id": "b73aaBDxqSYb",
    "outputId": "edc9f85b-0e83-4d89-90c8-f7f15c009794"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ENCODER:\n",
      " -----------------------------------------------------------------------\n",
      "      Layer (type)         Input Shape         Param #     Tr. Param #\n",
      "=======================================================================\n",
      "          Linear-1            [1, 784]          21,980          21,980\n",
      "       LeakyReLU-2             [1, 28]               0               0\n",
      "          Linear-3             [1, 28]             812             812\n",
      "       LeakyReLU-4             [1, 28]               0               0\n",
      "          Linear-5             [1, 28]           1,624           1,624\n",
      "=======================================================================\n",
      "Total params: 24,416\n",
      "Trainable params: 24,416\n",
      "Non-trainable params: 0\n",
      "-----------------------------------------------------------------------\n",
      "\n",
      "\n",
      "========================== Hierarchical Summary ==========================\n",
      "\n",
      "Sequential(\n",
      "  (0): Linear(in_features=784, out_features=28, bias=True), 21,980 params\n",
      "  (1): LeakyReLU(negative_slope=0.01), 0 params\n",
      "  (2): Linear(in_features=28, out_features=28, bias=True), 812 params\n",
      "  (3): LeakyReLU(negative_slope=0.01), 0 params\n",
      "  (4): Linear(in_features=28, out_features=56, bias=True), 1,624 params\n",
      "), 24,416 params\n",
      "\n",
      "\n",
      "==========================================================================\n",
      "\n",
      "\n",
      "DECODER:\n",
      " -----------------------------------------------------------------------\n",
      "      Layer (type)         Input Shape         Param #     Tr. Param #\n",
      "=======================================================================\n",
      "          Linear-1             [1, 28]             812             812\n",
      "       LeakyReLU-2             [1, 28]               0               0\n",
      "          Linear-3             [1, 28]             812             812\n",
      "       LeakyReLU-4             [1, 28]               0               0\n",
      "          Linear-5             [1, 28]          22,736          22,736\n",
      "=======================================================================\n",
      "Total params: 24,360\n",
      "Trainable params: 24,360\n",
      "Non-trainable params: 0\n",
      "-----------------------------------------------------------------------\n",
      "\n",
      "\n",
      "========================== Hierarchical Summary ==========================\n",
      "\n",
      "Sequential(\n",
      "  (0): Linear(in_features=28, out_features=28, bias=True), 812 params\n",
      "  (1): LeakyReLU(negative_slope=0.01), 0 params\n",
      "  (2): Linear(in_features=28, out_features=28, bias=True), 812 params\n",
      "  (3): LeakyReLU(negative_slope=0.01), 0 params\n",
      "  (4): Linear(in_features=28, out_features=784, bias=True), 22,736 params\n",
      "), 24,360 params\n",
      "\n",
      "\n",
      "==========================================================================\n",
      "\n",
      "Encoder weight shapes: [torch.Size([28, 784]), torch.Size([28, 28]), torch.Size([56, 28])]\n",
      "Decoder weight shapes: [torch.Size([28, 28]), torch.Size([28, 28]), torch.Size([784, 28])]\n"
     ]
    }
   ],
   "source": [
    "D = 784   # input dimension\n",
    "L = 28  # number of latents\n",
    "M = 28 # the number of neurons in scale (s) and translation (t) nets\n",
    "\n",
    "likelihood_type = 'bernoulli'\n",
    "num_vals = 1\n",
    "\n",
    "encoder = nn.Sequential(nn.Linear(D, M), nn.LeakyReLU(),\n",
    "                        nn.Linear(M, M), nn.LeakyReLU(),\n",
    "                        nn.Linear(M, L*2))\n",
    "\n",
    "decoder = nn.Sequential(nn.Linear(L, M), nn.LeakyReLU(),\n",
    "                        nn.Linear(M, M), nn.LeakyReLU(),\n",
    "                        nn.Linear(M, D))\n",
    "\n",
    "\n",
    "prior = Prior(L=L)#torch.distributions.MultivariateNormal(torch.zeros(L), torch.eye(L))\n",
    "\n",
    "\n",
    "# Print the summary (like in Keras)\n",
    "print(\"ENCODER:\\n\", summary(encoder, torch.zeros(1, D), show_input=True, show_hierarchical=True))\n",
    "print(\"\\nDECODER:\\n\", summary(decoder, torch.zeros(1, L), show_input=True, show_hierarchical=True))\n",
    "\n",
    "\n",
    "print(f\"Encoder weight shapes: {[layer.weight.shape for layer in encoder if isinstance(layer, nn.Linear)]}\") #printing shapes for debugging\n",
    "print(f\"Decoder weight shapes: {[layer.weight.shape for layer in decoder if isinstance(layer, nn.Linear)]}\") # \"\"\n",
    "# FILL IN ANY OTHER HYPERPARAMS YOU WANT TO USE\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 379,
     "status": "ok",
     "timestamp": 1718301153412,
     "user": {
      "displayName": "shawn gibford",
      "userId": "13602589974876645014"
     },
     "user_tz": -120
    },
    "id": "N5kdnqbiSDmq",
    "outputId": "f6e47d69-61a5-4a6e-9db7-f7a9df9b2384"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VAE(\n",
       "  (encoder): Encoder(\n",
       "    (encoder): Sequential(\n",
       "      (0): Linear(in_features=784, out_features=28, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Linear(in_features=28, out_features=28, bias=True)\n",
       "      (3): LeakyReLU(negative_slope=0.01)\n",
       "      (4): Linear(in_features=28, out_features=56, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (decoder): Decoder(\n",
       "    (decoder): Sequential(\n",
       "      (0): Linear(in_features=28, out_features=28, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Linear(in_features=28, out_features=28, bias=True)\n",
       "      (3): LeakyReLU(negative_slope=0.01)\n",
       "      (4): Linear(in_features=28, out_features=784, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (prior): Prior()\n",
       ")"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# INIT YOUR VAE (PLEASE CALL IT model)\n",
    "# FILL IN\n",
    "model = VAE(encoder_net=encoder, decoder_net=decoder, num_vals=1, L=L, likelihood_type=likelihood_type)\n",
    "model.to(device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iC8AkWt4CURT"
   },
   "source": [
    "Please initialize the optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "executionInfo": {
     "elapsed": 353,
     "status": "ok",
     "timestamp": 1718301155797,
     "user": {
      "displayName": "shawn gibford",
      "userId": "13602589974876645014"
     },
     "user_tz": -120
    },
    "id": "a3nTSDe7ql08"
   },
   "outputs": [],
   "source": [
    "# PLEASE DEFINE YOUR OPTIMIZER\n",
    "lr = 3e-4 # learning rate (PLEASE CHANGE IT AS YOU WISH!)\n",
    "betas = (0.9, 0.999)\n",
    "eps = 1e-8\n",
    "optimizer = torch.optim.Adamax([p for p in model.parameters() if p.requires_grad == True], lr=lr, betas=betas, eps=eps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "79odxtRjCaix"
   },
   "source": [
    "#### Question 8\n",
    "\n",
    "Please explain the choice of the optimizer, and comment on the choice of the hyperparameters (e.g., the learing reate value)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cEjOlYN9Ft_B"
   },
   "source": [
    "ANSWER:\n",
    "\n",
    "ADAM - common choice for VAE as it is an adaptive learning rate optimizer. It combines Adaptive Gradient Algorithm and Root Mean Square Propogation, ie; it  combines momentum and scaling of the gradient.\n",
    "\n",
    "I added beta 1 and beta 2, as well as epsilon.\n",
    "\n",
    "Betas control exponential decay rates. Epsilon prevents division by zero."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P5GrzUcHFweG"
   },
   "source": [
    "### Training and final evaluation\n",
    "\n",
    "In the following two cells, we run the training and the final evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 365
    },
    "executionInfo": {
     "elapsed": 291,
     "status": "error",
     "timestamp": 1718301159306,
     "user": {
      "displayName": "shawn gibford",
      "userId": "13602589974876645014"
     },
     "user_tz": -120
    },
    "id": "VD7WuY6bqnBK",
    "outputId": "2762ca14-c664-4f81-d25d-c6b7c14b01ef"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, val nll=120.29863117370606\n",
      "saved!\n",
      "Epoch: 1, val nll=120.28796388244629\n",
      "saved!\n",
      "Epoch: 2, val nll=120.24742332763672\n",
      "saved!\n",
      "Epoch: 3, val nll=120.31174450683594\n",
      "Epoch: 4, val nll=120.27745465087891\n",
      "Epoch: 5, val nll=120.2750616973877\n",
      "Epoch: 6, val nll=120.30310242004394\n",
      "Epoch: 7, val nll=120.27761879272461\n",
      "Epoch: 8, val nll=120.24426590576172\n",
      "saved!\n",
      "Epoch: 9, val nll=120.29404556274415\n",
      "Epoch: 10, val nll=120.26303800048828\n",
      "Epoch: 11, val nll=120.23999944458008\n",
      "saved!\n",
      "Epoch: 12, val nll=120.22974952392578\n",
      "saved!\n",
      "Epoch: 13, val nll=120.2666642211914\n",
      "Epoch: 14, val nll=120.20893081970215\n",
      "saved!\n",
      "Epoch: 15, val nll=120.2164168182373\n",
      "Epoch: 16, val nll=120.31710451049804\n",
      "Epoch: 17, val nll=120.25669100952149\n",
      "Epoch: 18, val nll=120.24151962280274\n",
      "Epoch: 19, val nll=120.2675341369629\n",
      "Epoch: 20, val nll=120.25488601989746\n",
      "Epoch: 21, val nll=120.28549823608398\n",
      "Epoch: 22, val nll=120.2364026184082\n",
      "Epoch: 23, val nll=120.224358984375\n",
      "Epoch: 24, val nll=120.2525501953125\n",
      "Epoch: 25, val nll=120.31197967529297\n",
      "Epoch: 26, val nll=120.26446211547852\n",
      "Epoch: 27, val nll=120.3100105682373\n",
      "Epoch: 28, val nll=120.28245850524902\n",
      "Epoch: 29, val nll=120.27282121276855\n",
      "Epoch: 30, val nll=120.19485074157714\n",
      "saved!\n",
      "Epoch: 31, val nll=120.23218702392577\n",
      "Epoch: 32, val nll=120.29252074279785\n",
      "Epoch: 33, val nll=120.22237278442383\n",
      "Epoch: 34, val nll=120.23264096679688\n",
      "Epoch: 35, val nll=120.31038100585937\n",
      "Epoch: 36, val nll=120.21948461303711\n",
      "Epoch: 37, val nll=120.24668807983399\n",
      "Epoch: 38, val nll=120.20780910034179\n",
      "Epoch: 39, val nll=120.2371947265625\n",
      "Epoch: 40, val nll=120.24508889160157\n",
      "Epoch: 41, val nll=120.22905009460449\n",
      "Epoch: 42, val nll=120.26583775024415\n",
      "Epoch: 43, val nll=120.2322891418457\n",
      "Epoch: 44, val nll=120.3137717376709\n",
      "Epoch: 45, val nll=120.35522696838379\n",
      "Epoch: 46, val nll=120.31875712890626\n",
      "Epoch: 47, val nll=120.23836828308106\n",
      "Epoch: 48, val nll=120.20914146118164\n",
      "Epoch: 49, val nll=120.24376499023437\n",
      "Epoch: 50, val nll=120.24457405700683\n",
      "Epoch: 51, val nll=120.26157701416015\n"
     ]
    }
   ],
   "source": [
    "# ==========DO NOT REMOVE OR MODIFY==========\n",
    "# Training procedure\n",
    "nll_val = training(name='vae', max_patience=20,\n",
    "                   num_epochs=num_epochs, model=model, optimizer=optimizer,\n",
    "                   training_loader=train_loader, val_loader=val_loader,\n",
    "                   shape=(28,28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "aborted",
     "timestamp": 1718298603283,
     "user": {
      "displayName": "shawn gibford",
      "userId": "13602589974876645014"
     },
     "user_tz": -120
    },
    "id": "JAuMt9_wquOI"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FINAL LOSS: nll=119.74667811279296\n"
     ]
    }
   ],
   "source": [
    "# ==========DO NOT REMOVE OR MODIFY==========\n",
    "# Final evaluation\n",
    "test_loss = evaluation(name=result_dir + name, test_loader=test_loader)\n",
    "f = open(result_dir + name + '_test_loss.txt', \"w\")\n",
    "f.write(str(test_loss))\n",
    "f.close()\n",
    "\n",
    "samples_real(result_dir + name, test_loader)\n",
    "samples_generated(result_dir + name, test_loader, extra_name='_FINAL')\n",
    "\n",
    "plot_curve(result_dir + name, nll_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qaBwGtSJF8ag"
   },
   "source": [
    "### Results and discussion\n",
    "\n",
    "After a successful training of your model, we would like to ask you to present your data and analyze it. Please answer the following questions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v4WZkoiHFyZm"
   },
   "source": [
    "#### Question 9\n",
    "\n",
    "Please select the real data, and the final generated data and include them in this report. Please comment on the following:\n",
    "- Do you think the model was trained properly by looking at the generations? Please motivate your answer well.\n",
    "- What are the potential problems with evaluating a generative model by looking at generated data? How can we evaluate generative models (NOTE: ELBO or NLL do not count as answers)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z8yQ2T9GIuvc"
   },
   "source": [
    "ANSWER: \n",
    "1.  Subjectivity and bias will influence they way synthetic data is evaluated by a human. Also, just visually inspecting data will miss aspects of a distribution.\n",
    "Looking at the generated samples from differeing points in the training and the final, you will see holes in the images.\n",
    "But, in a word, no, I do not.\n",
    "\n",
    "2. FID- Frechet Inception Score claculates distance between distributions of real and generated data and gives a quantitative assesment of the quality of generated data.\n",
    "\n",
    "\n",
    "3. IS-Inception Scaore calculates the KL divergence between conditional and marginal label distributions. Measure of both the quality and diversity of new data.\n",
    "\n",
    "\n",
    "4. Precision/Recall- Measure of quality by verifying 'realness'. Recall looks at the coverage of real data distribution by the generated samples.\n",
    "\n",
    "\n",
    "5. KDE- Kernel Density Estimation guesses at the probability density function of the real and synthetic data, with metrics like Max Mean Discrepency MMD. It give a clear view of the closeness of the generated and real data.\n",
    "\n",
    "\n",
    "6. PPL-Perceptual Path Length looks at the smoothness/consitency of the generators latent space by computing the mean perceptual distence between interpolated samples.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"800\"\n",
       "            height=\"600\"\n",
       "            src=\"vae_real_images.pdf\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7ff6d8c4d010>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import IFrame\n",
    "IFrame(src='vae_real_images.pdf', width=800, height=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"800\"\n",
       "            height=\"600\"\n",
       "            src=\"vae_generated_images_epoch_1\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7ff6da387bd0>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IFrame(src='vae_generated_images_epoch_1', width=800, height=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"800\"\n",
       "            height=\"600\"\n",
       "            src=\"vae_generated_images_epoch_102\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7ff6d8219a90>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IFrame(src='vae_generated_images_epoch_102', width=800, height=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"800\"\n",
       "            height=\"600\"\n",
       "            src=\"vae_generated_images_FINAL.pdf\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7ff6d9915bd0>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IFrame(src='vae_generated_images_FINAL.pdf', width=800, height=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lmyH318fIwc9"
   },
   "source": [
    "#### Question 10\n",
    "\n",
    "Please include the plot of the negative ELBO. Please comment on the following:\n",
    "- Is the training of your VAE stable or unstable? Why?\n",
    "- What is the influence of the optimizer on your model? Do the hyperparameter values of the optimizer important and how do they influence the training? Motivate well your answer (e.g., run the script with more than one learning rate and present two plots here)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ANSWER:\n",
    "\n",
    "No. Seeing the holes in the images throughout the training generations and the final output shows that the training is unstable.\n",
    "\n",
    "The hyperparameters of the optimizer allow more control over how your model can be trained. By altering the learning rate you change how well the net work can learn the distripution. As seen here, by making the learning rate too small, the model will not learn. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"800\"\n",
       "            height=\"600\"\n",
       "            src=\"vae_nll_val_curve.pdf\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7ff6d917e810>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# NELBO PLot @ lr = 2e-3\n",
    "IFrame(src='vae_nll_val_curve.pdf', width=800, height=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"800\"\n",
       "            height=\"600\"\n",
       "            src=\"vae_nll_val_curve_new_lr.pdf\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7ff6d5f4ced0>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#NELBO Plot @ lr = 3e-4\n",
    "IFrame(src='vae_nll_val_curve_new_lr.pdf', width=800, height=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": [
    {
     "file_id": "1C6CaZsSdXdc5fONOVrJy5iYKzr2DIg9j",
     "timestamp": 1607008727578
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
